{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a trueskill model using pyro\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from scipy.special import expit as sigmoid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_variance = 5.0\n",
    "\n",
    "class TrueskillModel:\n",
    "     \n",
    "    def __init__(self, mus=None, sigmas=None):\n",
    "        if mus is None:\n",
    "            mus = []\n",
    "        if sigmas is None:\n",
    "            sigmas = []\n",
    "\n",
    "        if len(mus) != len(sigmas):\n",
    "            raise ValueError('mus and sigmas must have the same length')\n",
    "\n",
    "        self.mus = torch.tensor(mus)\n",
    "        self.sigmas = torch.tensor(sigmas)\n",
    "        self.rankings = torch.clamp((self.mus - 3*self.sigmas).int(), min=0)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.mus[i], self.sigmas[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mus)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return TrueskillModel(torch.cat((self.mus, other.mus)), torch.cat((self.sigmas, other.sigmas)))\n",
    "    \n",
    "    \n",
    "    def add_player(self, mu, sigma):\n",
    "        self.mus = torch.cat((self.mus, torch.tensor([mu])))\n",
    "        self.sigmas = torch.cat((self.sigmas, torch.tensor([sigma])))\n",
    "        self.rankings = torch.cat((self.rankings, torch.clamp((torch.tensor([mu - 3*sigma]).int()), min=0)))\n",
    "\n",
    "    def infer_matches(self, matches:list):\n",
    "        for match in matches:\n",
    "            self.infer_match(match)\n",
    "\n",
    "    def infer_match(self, match:dict):\n",
    "        \n",
    "        print('Infering match:', match['player1'], 'vs', match['player2'])\n",
    "\n",
    "        # Data\n",
    "        data = torch.tensor(match['outcome'])\n",
    "        hyperparameters = {\n",
    "            'mu1': self.mus[match['player1']],\n",
    "            'sigma1': self.sigmas[match['player1']],\n",
    "            'mu2': self.mus[match['player2']],\n",
    "            'sigma2': self.sigmas[match['player2']]\n",
    "        }\n",
    "        \n",
    "        # Optimizer\n",
    "        adam_params = {\"lr\": 0.01}\n",
    "        optimizer = Adam(adam_params)\n",
    "\n",
    "        # SVI\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "        # Inference\n",
    "        for step in tqdm(range(1000)):\n",
    "            loss = svi.step(data, hyperparameters)\n",
    "            # if step % 100 == 0:\n",
    "            #     print('step: {} loss: {}'.format(step, loss))\n",
    "        \n",
    "        # Update\n",
    "        self.mus[match['player1']] = pyro.param('mu1').item()\n",
    "        self.sigmas[match['player1']] = pyro.param('sigma1').item()\n",
    "        self.mus[match['player2']] = pyro.param('mu2').item()\n",
    "        self.sigmas[match['player2']] = pyro.param('sigma2').item()\n",
    "        self.rankings[match['player1']] = torch.clamp((self.mus[match['player1']] - 3*self.sigmas[match['player1']]).int(), min=0)\n",
    "        self.rankings[match['player2']] = torch.clamp((self.mus[match['player2']] - 3*self.sigmas[match['player2']]).int(), min=0)\n",
    "\n",
    "\n",
    "    def model(self, data:torch.Tensor, hyperparameters:dict):\n",
    "\n",
    "        # Hyperparameters\n",
    "        mu1 = hyperparameters['mu1']\n",
    "        sigma1 = hyperparameters['sigma1']\n",
    "        mu2 = hyperparameters['mu2']\n",
    "        sigma2 = hyperparameters['sigma2']\n",
    "\n",
    "        # Skill\n",
    "        s1 = pyro.sample('skill1', dist.Normal(mu1, sigma1))\n",
    "        s2 = pyro.sample('skill2', dist.Normal(mu2, sigma2))\n",
    "\n",
    "        # Performance\n",
    "        p1 = pyro.sample('perf1', dist.Normal(s1, perf_variance))\n",
    "        p2 = pyro.sample('perf2', dist.Normal(s2, perf_variance))\n",
    "\n",
    "        # # Draw margin\n",
    "        # m = pyro.sample('margin', dist.Normal(1, torch.sqrt(10)))\n",
    "\n",
    "        # Outcome\n",
    "        diff = p1 - p2\n",
    "        return pyro.sample('outcome', dist.Bernoulli(logits=diff), obs=data.float())\n",
    "\n",
    "\n",
    "    def guide(self, data:torch.Tensor, hyperparameters:dict):\n",
    "        \n",
    "        # Hyperparameters\n",
    "        mu1 = pyro.param('mu1', hyperparameters['mu1'])\n",
    "        sigma1 = pyro.param('sigma1', hyperparameters['sigma1'], constraint=dist.constraints.positive)\n",
    "        mu2 = pyro.param('mu2', hyperparameters['mu2'])\n",
    "        sigma2 = pyro.param('sigma2', hyperparameters['sigma2'], constraint=dist.constraints.positive)\n",
    "\n",
    "        # Skill\n",
    "        pyro.sample('skill1', dist.Normal(mu1, sigma1))\n",
    "        pyro.sample('skill2', dist.Normal(mu2, sigma2))\n",
    "\n",
    "        # Performance\n",
    "        pyro.sample('perf1', dist.Normal(mu1, perf_variance))\n",
    "        pyro.sample('perf2', dist.Normal(mu2, perf_variance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mus = [108.4022, 124.4276,  87.8523, 122.9843, 106.9173, 110.6769,  74.3508, 75.0743,  94.3534,  90.7460, 287.1037]\n",
    "# sigma = [1.4091e+00, 2.4500e-02, 1.5174e-10, 5.6699e+00, 9.6327e-01, 1.2125e-01, 5.1401e+00, 9.4271e-02, 1.6267e+00, 9.4192e-02, 6.4496e-04]\n",
    "\n",
    "num_players = 10\n",
    "\n",
    "mus = np.ones(num_players)*100.\n",
    "sigmas = np.ones(num_players)*40.\n",
    "\n",
    "model = TrueskillModel(mus, sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run random matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rankings: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Infering match: 7 vs 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 108.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering match: 9 vs 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 131.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering match: 6 vs 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 132.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering match: 7 vs 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 127.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering match: 9 vs 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 135.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering match: 5 vs 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 129.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering match: 3 vs 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 134.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering match: 5 vs 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 137.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering match: 1 vs 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 136.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering match: 3 vs 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 136.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rankings: tensor([89, 86, 98, 96,  0, 91, 93, 90,  0, 89], dtype=torch.int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate random matches for players\n",
    "num_matches = 10\n",
    "matches = []\n",
    "for i in range(10):\n",
    "    # Draw 2 random players that are not the same\n",
    "    player1, player2 = np.random.choice(10, 2, replace=False)\n",
    "    outcome = np.random.choice([0, 1])\n",
    "    matches.append({'player1': player1, 'player2': player2, 'outcome': outcome})\n",
    "\n",
    "print('Initial rankings:', model.rankings)\n",
    "model.infer_matches(matches)\n",
    "print('Final rankings:', model.rankings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
