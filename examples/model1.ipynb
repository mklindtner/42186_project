{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from paths import mkl_data\n",
    "import requests # API library\n",
    "\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from isoweek import Week\n",
    "\n",
    "import requests # API library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n",
    "from pyro.infer import Predictive\n",
    "\n",
    "import torch\n",
    "\n",
    "# Pyro-specific imports\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_m1 = pd.read_csv('../df_matches_clean.csv')\n",
    "df_m1 = pd.read_csv('../data/X_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toy Model - we assume that all skills are normal distributed with mean 0 and std 1\n",
    "def simple_model(obs=None):\n",
    "    skill1 = pyro.sample(\"skill1\", dist.Normal(0., 1.))\n",
    "    skill2 = pyro.sample(\"skill2\", dist.Normal(0., 1.))\n",
    "\n",
    "    sigma1 = 1; sigma2 = 2\n",
    "    perf1 = pyro.sample(\"perf1\", dist.Normal(skill1, sigma1))\n",
    "    perf2 = pyro.sample(\"perf2\", dist.Normal(skill2, sigma2))\n",
    "\n",
    "    with pyro.plate(\"data\", len(obs)):\n",
    "        y = pyro.sample(\"obs\", dist.Categorical(), obs=obs)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "def simple_model2(obs=None):\n",
    "    mu1 = pyro.sample(\"mu1\", dist.Normal(0., 1.))\n",
    "    mu2 = pyro.sample(\"mu2\", dist.Normal(0., 1.))\n",
    "\n",
    "    sigma1 = pyro.sample(\"sigma1\", dist.HalfNormal(1.))\n",
    "    sigma2 = pyro.sample(\"sigma2\", dist.HalfNormal(1.))\n",
    "    \n",
    "    skill1 = pyro.sample(\"skill1\", dist.Normal(mu1, sigma1))\n",
    "    skill2 = pyro.sample(\"skill2\", dist.Normal(mu2, sigma2))\n",
    "\n",
    "    sigma1 = 1\n",
    "    sigma2 = 2\n",
    "    perf1 = pyro.sample(\"perf1\", dist.Normal(skill1, sigma1))\n",
    "    perf2 = pyro.sample(\"perf2\", dist.Normal(skill2, sigma2))\n",
    "\n",
    "    # Calculate performance difference\n",
    "    perf_diff = perf1 - perf2\n",
    "\n",
    "    # Translate performance difference into a vector of outcome probabilities\n",
    "    # The scaling factor 'scale' can be adjusted to control the spread\n",
    "    scale = torch.tensor(1.0)\n",
    "    logits = torch.tensor([-1., 0., 1.]) * perf_diff * scale\n",
    "    probabilities = torch.softmax(logits, 0)\n",
    "\n",
    "    with pyro.plate(\"data\", len(obs) if obs is not None else 1):\n",
    "        # Map observed outcomes to indices for the Categorical distribution\n",
    "        if obs is not None:\n",
    "            obs_indices = (torch.tensor(obs) + 1).long()\n",
    "        else:\n",
    "            obs_indices = None\n",
    "\n",
    "        # Sample the observation or score it against the model\n",
    "        cat = pyro.sample(\"obs\", dist.Categorical(probabilities), obs=obs_indices)\n",
    "        \n",
    "        # If we are not conditioning on observed data, map the sample back to [-1, 0, 1]\n",
    "        y = torch.tensor([-1, 0, 1])[cat.long()] if obs is None else obs\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.render_model(model, model_args=(None, None), render_distributions=True)\n",
    "\n",
    "#Make guide and optimizer\n",
    "model = simple_model2\n",
    "auto_guide = pyro.infer.autoguide.AutoNormal(model)\n",
    "adam = pyro.optim.Adam({\"lr\": 0.02})\n",
    "elbo = pyro.infer.Trace_ELBO()\n",
    "svi = pyro.infer.SVI(model, auto_guide, adam, elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bx/n7x8tlw17p9_m_8d4g08505w0000gn/T/ipykernel_15434/1152732824.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  obs_indices = (torch.tensor(obs) + 1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ELBO: 84261.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bx/n7x8tlw17p9_m_8d4g08505w0000gn/T/ipykernel_15434/1152732824.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  obs_indices = (torch.tensor(obs) + 1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100] ELBO: 83910.6\n",
      "[200] ELBO: 83746.9\n",
      "[300] ELBO: 83680.3\n",
      "[400] ELBO: 83663.0\n",
      "[500] ELBO: 84020.3\n",
      "[600] ELBO: 83668.4\n",
      "[700] ELBO: 83700.4\n",
      "[800] ELBO: 83646.4\n",
      "[900] ELBO: 83696.7\n",
      "CPU times: user 26.4 s, sys: 1min 31s, total: 1min 57s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Clear param store \n",
    "pyro.clear_param_store()\n",
    "\n",
    "# These should be reset each training loop.\n",
    "auto_guide = pyro.infer.autoguide.AutoNormal(model)\n",
    "adam = pyro.optim.Adam({\"lr\": 0.005}) \n",
    "elbo = pyro.infer.Trace_ELBO(num_particles=3)\n",
    "svi = pyro.infer.SVI(model, auto_guide, adam, elbo)\n",
    "\n",
    "\n",
    "# Do gradient steps\n",
    "n_steps = 1000\n",
    "X_torch = torch.tensor(df_m1['team1_win'].values, dtype=torch.int32)\n",
    "for step in range(n_steps):\n",
    "    elbo = svi.step(X_torch)\n",
    "    if step % 100 == 0:\n",
    "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "42186_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
