{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from paths import mkl_data\n",
    "import requests # API library\n",
    "\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from isoweek import Week\n",
    "\n",
    "import requests # API library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n",
    "from pyro.infer import Predictive\n",
    "\n",
    "import torch\n",
    "\n",
    "# Pyro-specific imports\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_m1 = pd.read_csv('../df_matches_clean.csv')\n",
    "df_m1 = pd.read_csv('../data/X_train.csv')\n",
    "df_m1_test = pd.read_csv('../data/X_test.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toy Model - we assume that all skills are normal distributed with mean 0 and std 1\n",
    "def simple_model(obs=None):\n",
    "    skill1 = pyro.sample(\"skill1\", dist.Normal(0., 1.))\n",
    "    skill2 = pyro.sample(\"skill2\", dist.Normal(0., 1.))\n",
    "\n",
    "    sigma1 = 1; sigma2 = 2\n",
    "    perf1 = pyro.sample(\"perf1\", dist.Normal(skill1, sigma1))\n",
    "    perf2 = pyro.sample(\"perf2\", dist.Normal(skill2, sigma2))\n",
    "\n",
    "    with pyro.plate(\"data\", len(obs)):\n",
    "        y = pyro.sample(\"obs\", dist.Categorical(), obs=obs)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "def simple_model2(obs=None):\n",
    "    mu1 = pyro.sample(\"mu1\", dist.Normal(0., 1.))\n",
    "    mu2 = pyro.sample(\"mu2\", dist.Normal(0., 1.))\n",
    "\n",
    "    sigma1 = pyro.sample(\"sigma1\", dist.HalfNormal(1.))\n",
    "    sigma2 = pyro.sample(\"sigma2\", dist.HalfNormal(1.))\n",
    "    \n",
    "    skill1 = pyro.sample(\"skill1\", dist.Normal(mu1, sigma1))\n",
    "    skill2 = pyro.sample(\"skill2\", dist.Normal(mu2, sigma2))\n",
    "\n",
    "    sigma1 = 1\n",
    "    sigma2 = 2\n",
    "    perf1 = pyro.sample(\"perf1\", dist.Normal(skill1, sigma1))\n",
    "    perf2 = pyro.sample(\"perf2\", dist.Normal(skill2, sigma2))\n",
    "\n",
    "    # Calculate performance difference\n",
    "    perf_diff = perf1 - perf2\n",
    "\n",
    "    # Translate performance difference into a vector of outcome probabilities\n",
    "    # The scaling factor 'scale' can be adjusted to control the spread\n",
    "    scale = torch.tensor(1.0)\n",
    "    logits = torch.tensor([-1., 0., 1.]) * perf_diff * scale\n",
    "    probabilities = torch.softmax(logits, 0)\n",
    "\n",
    "    with pyro.plate(\"data\", len(obs) if obs is not None else 1):\n",
    "        # Map observed outcomes to indices for the Categorical distribution\n",
    "        if obs is not None:\n",
    "            obs_indices = (torch.tensor(obs) + 1).long()\n",
    "        else:\n",
    "            obs_indices = None\n",
    "\n",
    "        # Sample the observation or score it against the model\n",
    "        cat = pyro.sample(\"obs\", dist.Categorical(probabilities), obs=obs_indices)\n",
    "        \n",
    "        # If we are not conditioning on observed data, map the sample back to [-1, 0, 1]\n",
    "        y = torch.tensor([-1, 0, 1])[cat.long()] if obs is None else obs\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.render_model(model, model_args=(None, None), render_distributions=True)\n",
    "\n",
    "#Make guide and optimizer\n",
    "model = simple_model2\n",
    "auto_guide = pyro.infer.autoguide.AutoNormal(model)\n",
    "adam = pyro.optim.Adam({\"lr\": 0.02})\n",
    "elbo = pyro.infer.Trace_ELBO()\n",
    "svi = pyro.infer.SVI(model, auto_guide, adam, elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bx/n7x8tlw17p9_m_8d4g08505w0000gn/T/ipykernel_15434/1152732824.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  obs_indices = (torch.tensor(obs) + 1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ELBO: 84303.0\n",
      "[100] ELBO: 83687.2\n",
      "[200] ELBO: 84007.6\n",
      "[300] ELBO: 83857.8\n",
      "[400] ELBO: 83834.4\n",
      "[500] ELBO: 83682.6\n",
      "[600] ELBO: 83711.0\n",
      "[700] ELBO: 83647.1\n",
      "[800] ELBO: 83669.6\n",
      "[900] ELBO: 83658.3\n",
      "CPU times: user 39.6 s, sys: 1min 29s, total: 2min 9s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Clear param store \n",
    "pyro.clear_param_store()\n",
    "\n",
    "# These should be reset each training loop.\n",
    "auto_guide = pyro.infer.autoguide.AutoNormal(model)\n",
    "adam = pyro.optim.Adam({\"lr\": 0.005}) \n",
    "elbo = pyro.infer.Trace_ELBO(num_particles=3)\n",
    "svi = pyro.infer.SVI(model, auto_guide, adam, elbo)\n",
    "\n",
    "\n",
    "# Do gradient steps\n",
    "n_steps = 1000\n",
    "X_torch = torch.tensor(df_m1['team1_win'].values, dtype=torch.int32)\n",
    "for step in range(n_steps):\n",
    "    elbo = svi.step(X_torch)\n",
    "    if step % 100 == 0:\n",
    "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X_test \u001b[38;5;241m=\u001b[39m df_m1_test\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam1_win\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(X_test)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# X_test = df_m1_test.drop('team1_win', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume `test_data` is a list of (winner, loser) pairs\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "#df_m1 = pd.read_csv('../data/X_train.csv')\n",
    "#df_m1_test = pd.read_csv('../data/X_test.csv')  \n",
    "\n",
    "for winner, loser in test_data:\n",
    "    # Use the model to predict the outcome of the game\n",
    "    win_prob = predict(winner, loser)  # Assume `predict` is a function that uses the model to predict the win probability\n",
    "    predicted_outcome = 1 if win_prob > 0.5 else 0\n",
    "    actual_outcome = 1 if winner > loser else 0  # Assume the winner has a higher skill\n",
    "\n",
    "    # Update the count of correct predictions\n",
    "    if predicted_outcome == actual_outcome:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    total_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "42186_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
