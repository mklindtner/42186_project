{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tripl\\AppData\\Local\\Temp\\ipykernel_16256\\3264193253.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "C:\\Users\\tripl\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from paths import mkl_data\n",
    "import requests # API library\n",
    "\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from isoweek import Week\n",
    "\n",
    "import requests # API library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n",
    "from pyro.infer import Predictive\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "my_data_path = \"df_matches.csv\"\n",
    "df = pd.read_csv(my_data_path, sep=',')\n",
    "# Drop rows with missing values\n",
    "# df = df.dropna(subset=['match_date','match_conceded', 'coach1_CR', 'coach2_CR'])\n",
    "\n",
    "relevant = [\"match_id\", \"division_name\", \"match_date\", \"match_time\", \"match_conceded\",\n",
    "            \"team1_coach_id\", \"team1_race_name\", \"team2_coach_id\", \"team2_race_name\",\n",
    "            \"team1_score\", \"team2_score\",\"team1_win\",\"team2_win\",\"mirror_match\",\n",
    "            \"coach1_ranking\",\"coach2_ranking\",\"coach1_CR\",\"coach2_CR\", \"team1_roster_id\", \"team2_roster_id\"]\n",
    "#irrelevant_columns = set(df.columns) - set(relevant)\n",
    "\n",
    "irrelevant_columns = {\n",
    "    'tournament_name', 'week_year', 'cr_diff2', 'team1_cas_bh',\n",
    "    'group_name', 'team2_foul', 'team2_id', 'coach2_CR_bin',\n",
    "    'team1_id', 'year', 'week_date', 'week_number', 'replay_id',\n",
    "    'team1_cas_rip', 'tv_diff', 'team2_block', 'coach1_CR_bin',\n",
    "    'has_sp', 'team2_value', 'tournament_type', 'team1_value',\n",
    "    'team2_comp', 'team1_rush', 'team1_foul', 'team2_inducements',\n",
    "    'tv_diff2', 'tournament_start', 'team2_cas_rip', 'team1_inducements',\n",
    "    'tv_bin', 'scheduler', 'team1_comp', 'cr_diff2_bin', 'group_id',\n",
    "    'division_id', 'tournament_id', 'Unnamed: 0', 'team2_cas_si',\n",
    "    'current_ruleset', 'team2_cas', 'team2_rush', 'team1_block',\n",
    "    'tournament_end', 'team2_pass', 'team1_cas',\n",
    "    'CR_diff', 'team1_cas_si', 'team2_cas_bh', 'team1_pass', 'tv_match',\n",
    "    'tv_bin2', 'tournament_progression'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first load from the competitve league, then filter out the relevant columns\n",
    "df_matches_competitive = df[df['division_name'] == 'Competitive']\n",
    "df_matches = df_matches_competitive[relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tripl\\AppData\\Local\\Temp\\ipykernel_16256\\626055672.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matches['match_date'] = pd.to_datetime(df_matches.match_date) # Datetime object\n",
      "C:\\Users\\tripl\\AppData\\Local\\Temp\\ipykernel_16256\\626055672.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matches['team1_win'] = np.sign(df_matches['team1_score'] - df_matches['team2_score'])\n",
      "C:\\Users\\tripl\\AppData\\Local\\Temp\\ipykernel_16256\\626055672.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matches['team2_win'] = np.sign(df_matches['team2_score'] - df_matches['team1_score'])\n",
      "C:\\Users\\tripl\\AppData\\Local\\Temp\\ipykernel_16256\\626055672.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matches['mirror_match'] = 0\n"
     ]
    }
   ],
   "source": [
    "#Fix types in pandas\n",
    "\n",
    "# # convert object dtype columns to proper pandas dtypes datetime and numeric\n",
    "df_matches['match_date'] = pd.to_datetime(df_matches.match_date) # Datetime object\n",
    "\n",
    "# calculate match score difference\n",
    "df_matches['team1_win'] = np.sign(df_matches['team1_score'] - df_matches['team2_score'])\n",
    "df_matches['team2_win'] = np.sign(df_matches['team2_score'] - df_matches['team1_score'])\n",
    "\n",
    "# mirror match\n",
    "df_matches['mirror_match'] = 0\n",
    "df_matches.loc[df_matches['team1_race_name'] == df_matches['team2_race_name'], 'mirror_match'] = 1\n",
    "\n",
    "\n",
    "# mirror matches\n",
    "df_matches = df_matches.dropna(subset=['match_date'])\n",
    "\n",
    "df_matches['week_number'] = df_matches['match_date'].dt.isocalendar().week\n",
    "\n",
    "# cannot serialize numpy int OR Int64 when writing HDF5 file, so we go for plain int as all NAs are gone now\n",
    "df_matches['week_number'] = df_matches['week_number'].fillna(0).astype(int)\n",
    "\n",
    "# add year based on match ISO week\n",
    "df_matches['year'] = df_matches['match_date'].dt.isocalendar().year.astype(int)\n",
    "\n",
    "df_matches['week_year'] = df_matches['year'].astype(str) + '-' + df_matches['week_number'].astype(str)\n",
    "\n",
    "# use a lambda function since isoweek.Week is not vectorized \n",
    "df_matches['week_date'] = pd.to_datetime(df_matches.apply(lambda row : Week(int(row[\"year\"]),int(row[\"week_number\"])).monday(),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match_id', 'division_name', 'match_date', 'match_time',\n",
       "       'match_conceded', 'team1_coach_id', 'team1_race_name', 'team2_coach_id',\n",
       "       'team2_race_name', 'team1_score', 'team2_score', 'team1_win',\n",
       "       'team2_win', 'mirror_match', 'coach1_ranking', 'coach2_ranking',\n",
       "       'coach1_CR', 'coach2_CR', 'team1_roster_id', 'team2_roster_id',\n",
       "       'week_number', 'year', 'week_year', 'week_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 95193 entries, 108588 to 258150\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   week_date        95193 non-null  datetime64[ns]\n",
      " 1   match_time       95193 non-null  object        \n",
      " 2   team1_coach_id   95193 non-null  int64         \n",
      " 3   team2_coach_id   95193 non-null  int64         \n",
      " 4   team1_win        95193 non-null  int64         \n",
      " 5   team2_win        95193 non-null  int64         \n",
      " 6   team1_race_name  95193 non-null  category      \n",
      " 7   team2_race_name  95193 non-null  category      \n",
      "dtypes: category(2), datetime64[ns](1), int64(4), object(1)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#The selected columns from the competitive dataframe \n",
    "selected_columns = [\n",
    "    'week_date', \n",
    "    'match_time',\n",
    "    'team1_coach_id', \n",
    "    'team2_coach_id',\n",
    "    'team1_win', \n",
    "    'team2_win', \n",
    "    'team1_race_name', \n",
    "    'team2_race_name'\n",
    "]\n",
    "\n",
    "#final dataframe \n",
    "new_df = df_matches[selected_columns].copy()\n",
    "new_df['team1_race_name'] = new_df['team1_race_name'].astype('category')\n",
    "new_df['team2_race_name'] = new_df['team2_race_name'].astype('category')\n",
    "\n",
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Tomb Kings 3160.0 6108.0 0.5173542894564506\n",
      "1 Chaos Renegade 2389.5 5683.0 0.420464543374978\n",
      "2 High Elf 2008.0 4080.0 0.492156862745098\n",
      "3 Imperial Nobility 2471.0 5729.0 0.4313143655088148\n",
      "4 Lizardmen 3413.5 7032.0 0.48542377701934014\n",
      "5 Chaos Dwarf 4583.0 8587.0 0.5337137533480844\n",
      "6 Black Orc 3911.5 9084.0 0.4305922501100837\n",
      "7 Chaos Chosen 3086.5 6809.0 0.4532971067704509\n",
      "8 Amazon 3962.0 6357.0 0.6232499606732735\n",
      "9 Old World Alliance 1637.0 3583.0 0.45687970974044095\n",
      "10 Necromantic Horror 4388.0 8640.0 0.5078703703703704\n",
      "11 Vampire 1143.0 3093.0 0.36954413191076624\n",
      "12 Goblin 2170.5 5947.0 0.3649739364385404\n",
      "13 Dark Elf 3848.0 7394.0 0.5204219637543954\n",
      "14 Human 4717.5 8745.0 0.5394511149228131\n",
      "15 Orc 7527.0 13037.0 0.5773567538544143\n",
      "16 Shambling Undead 4724.0 8027.0 0.5885137660396162\n",
      "17 Wood Elf 2631.5 5497.0 0.47871566308895763\n",
      "18 Skaven 4317.0 7943.0 0.5434974191111671\n",
      "19 Underworld Denizens 4872.5 7754.0 0.6283853494970338\n",
      "20 Dwarf 4440.5 8141.0 0.545448962043975\n",
      "21 Ogre 2420.0 6270.0 0.38596491228070173\n",
      "22 Elven Union 1905.0 3967.0 0.4802117469120242\n",
      "23 Norse 4637.5 8834.0 0.5249603803486529\n",
      "24 Halfling 1379.5 3402.0 0.4054967666078777\n",
      "25 Snotling 2028.5 3766.0 0.5386351566648965\n",
      "26 Nurgle 2056.5 4750.0 0.43294736842105264\n",
      "27 Khorne 3752.0 9105.0 0.41208127402526085\n"
     ]
    }
   ],
   "source": [
    "#Store the cleaned data in your local directory \n",
    "new_df.to_csv('../df_matches_clean.csv', index=False)\n",
    "\n",
    "#print all values of team1_race_name\n",
    "races = new_df[\"team1_race_name\"].unique()\n",
    "\n",
    "num_games_race = np.zeros(len(races))\n",
    "points_race = np.zeros(len(races))\n",
    "\n",
    "\n",
    "for i in range(len(races)):\n",
    "    # Calculate num games by race\n",
    "    race_df = new_df[(new_df[\"team1_race_name\"] == races[i]) | (new_df[\"team2_race_name\"] == races[i])]\n",
    "    num_games_race[i] = race_df.shape[0]\n",
    "\n",
    "    # Calculate points by race\n",
    "    mask = race_df['team2_race_name'] == races[i]\n",
    "    race_df.loc[mask, 'team2_win'] *= -1\n",
    "    race_df.loc[mask, 'team1_win'] *= -1\n",
    "\n",
    "    points_race[i] = race_df[race_df['team1_win'] == 1].shape[0] + race_df[race_df['team1_win'] == 0].shape[0]/2\n",
    "\n",
    "\n",
    "for i in range(len(races)):\n",
    "    print(i, races[i], points_race[i], num_games_race[i], points_race[i]/num_games_race[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3160.  2389.5 2008.  2471.  3413.5 4583.  3911.5 3086.5 3962.  1637.\n",
      " 4388.  1143.  2170.5 3848.  4717.5 7527.  4724.  2631.5 4317.  4872.5\n",
      " 4440.5 2420.  1905.  4637.5 1379.5 2028.5 2056.5 3752. ]\n",
      "[ 6108.  5683.  4080.  5729.  7032.  8587.  9084.  6809.  6357.  3583.\n",
      "  8640.  3093.  5947.  7394.  8745. 13037.  8027.  5497.  7943.  7754.\n",
      "  8141.  6270.  3967.  8834.  3402.  3766.  4750.  9105.]\n",
      "[0.51735429 0.42046454 0.49215686 0.43131437 0.48542378 0.53371375\n",
      " 0.43059225 0.45329711 0.62324996 0.45687971 0.50787037 0.36954413\n",
      " 0.36497394 0.52042196 0.53945111 0.57735675 0.58851377 0.47871566\n",
      " 0.54349742 0.62838535 0.54544896 0.38596491 0.48021175 0.52496038\n",
      " 0.40549677 0.53863516 0.43294737 0.41208127]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "42186_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
