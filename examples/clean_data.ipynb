{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bx/n7x8tlw17p9_m_8d4g08505w0000gn/T/ipykernel_2687/3264193253.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/Users/fluffysnail/Library/CloudStorage/OneDrive-Personal/dtu/current/42186_modelml/42186_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from paths import mkl_data\n",
    "import requests # API library\n",
    "\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from isoweek import Week\n",
    "\n",
    "import requests # API library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n",
    "from pyro.infer import Predictive\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "my_data_path = \"df_matches.csv\"\n",
    "df = pd.read_csv(my_data_path, sep=',')\n",
    "# Drop rows with missing values\n",
    "# df = df.dropna(subset=['match_date','match_conceded', 'coach1_CR', 'coach2_CR'])\n",
    "\n",
    "relevant = [\"match_id\", \"division_name\", \"match_date\", \"match_time\", \"match_conceded\",\n",
    "            \"team1_coach_id\", \"team1_race_name\", \"team2_coach_id\", \"team2_race_name\",\n",
    "            \"team1_score\", \"team2_score\",\"team1_win\",\"team2_win\",\"mirror_match\",\n",
    "            \"coach1_ranking\",\"coach2_ranking\",\"coach1_CR\",\"coach2_CR\", \"team1_roster_id\", \"team2_roster_id\"]\n",
    "#irrelevant_columns = set(df.columns) - set(relevant)\n",
    "\n",
    "irrelevant_columns = {\n",
    "    'tournament_name', 'week_year', 'cr_diff2', 'team1_cas_bh',\n",
    "    'group_name', 'team2_foul', 'team2_id', 'coach2_CR_bin',\n",
    "    'team1_id', 'year', 'week_date', 'week_number', 'replay_id',\n",
    "    'team1_cas_rip', 'tv_diff', 'team2_block', 'coach1_CR_bin',\n",
    "    'has_sp', 'team2_value', 'tournament_type', 'team1_value',\n",
    "    'team2_comp', 'team1_rush', 'team1_foul', 'team2_inducements',\n",
    "    'tv_diff2', 'tournament_start', 'team2_cas_rip', 'team1_inducements',\n",
    "    'tv_bin', 'scheduler', 'team1_comp', 'cr_diff2_bin', 'group_id',\n",
    "    'division_id', 'tournament_id', 'Unnamed: 0', 'team2_cas_si',\n",
    "    'current_ruleset', 'team2_cas', 'team2_rush', 'team1_block',\n",
    "    'tournament_end', 'team2_pass', 'team1_cas',\n",
    "    'CR_diff', 'team1_cas_si', 'team2_cas_bh', 'team1_pass', 'tv_match',\n",
    "    'tv_bin2', 'tournament_progression'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first load from the competitve league, then filter out the relevant columns\n",
    "df_matches_competitive = df[df['division_name'] == 'Competitive']\n",
    "df_matches = df_matches_competitive[relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bx/n7x8tlw17p9_m_8d4g08505w0000gn/T/ipykernel_2687/626055672.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matches['match_date'] = pd.to_datetime(df_matches.match_date) # Datetime object\n",
      "/var/folders/bx/n7x8tlw17p9_m_8d4g08505w0000gn/T/ipykernel_2687/626055672.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matches['team1_win'] = np.sign(df_matches['team1_score'] - df_matches['team2_score'])\n",
      "/var/folders/bx/n7x8tlw17p9_m_8d4g08505w0000gn/T/ipykernel_2687/626055672.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matches['team2_win'] = np.sign(df_matches['team2_score'] - df_matches['team1_score'])\n",
      "/var/folders/bx/n7x8tlw17p9_m_8d4g08505w0000gn/T/ipykernel_2687/626055672.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matches['mirror_match'] = 0\n"
     ]
    }
   ],
   "source": [
    "#Fix types in pandas\n",
    "\n",
    "# # convert object dtype columns to proper pandas dtypes datetime and numeric\n",
    "df_matches['match_date'] = pd.to_datetime(df_matches.match_date) # Datetime object\n",
    "\n",
    "# calculate match score difference\n",
    "df_matches['team1_win'] = np.sign(df_matches['team1_score'] - df_matches['team2_score'])\n",
    "df_matches['team2_win'] = np.sign(df_matches['team2_score'] - df_matches['team1_score'])\n",
    "\n",
    "# mirror match\n",
    "df_matches['mirror_match'] = 0\n",
    "df_matches.loc[df_matches['team1_race_name'] == df_matches['team2_race_name'], 'mirror_match'] = 1\n",
    "\n",
    "\n",
    "# mirror matches\n",
    "df_matches = df_matches.dropna(subset=['match_date'])\n",
    "\n",
    "df_matches['week_number'] = df_matches['match_date'].dt.isocalendar().week\n",
    "\n",
    "# cannot serialize numpy int OR Int64 when writing HDF5 file, so we go for plain int as all NAs are gone now\n",
    "df_matches['week_number'] = df_matches['week_number'].fillna(0).astype(int)\n",
    "\n",
    "# add year based on match ISO week\n",
    "df_matches['year'] = df_matches['match_date'].dt.isocalendar().year.astype(int)\n",
    "\n",
    "df_matches['week_year'] = df_matches['year'].astype(str) + '-' + df_matches['week_number'].astype(str)\n",
    "\n",
    "# use a lambda function since isoweek.Week is not vectorized \n",
    "df_matches['week_date'] = pd.to_datetime(df_matches.apply(lambda row : Week(int(row[\"year\"]),int(row[\"week_number\"])).monday(),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match_id', 'division_name', 'match_date', 'match_time',\n",
       "       'match_conceded', 'team1_coach_id', 'team1_race_name', 'team2_coach_id',\n",
       "       'team2_race_name', 'team1_score', 'team2_score', 'team1_win',\n",
       "       'team2_win', 'mirror_match', 'coach1_ranking', 'coach2_ranking',\n",
       "       'coach1_CR', 'coach2_CR', 'team1_roster_id', 'team2_roster_id',\n",
       "       'week_number', 'year', 'week_year', 'week_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 95193 entries, 108588 to 258150\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   week_date        95193 non-null  datetime64[ns]\n",
      " 1   match_time       95193 non-null  object        \n",
      " 2   team1_coach_id   95193 non-null  int64         \n",
      " 3   team2_coach_id   95193 non-null  int64         \n",
      " 4   team1_win        95193 non-null  int64         \n",
      " 5   team2_win        95193 non-null  int64         \n",
      " 6   team1_race_name  95193 non-null  category      \n",
      " 7   team2_race_name  95193 non-null  category      \n",
      "dtypes: category(2), datetime64[ns](1), int64(4), object(1)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#The selected columns from the competitive dataframe \n",
    "selected_columns = [\n",
    "    'week_date', \n",
    "    'match_time',\n",
    "    'team1_coach_id', \n",
    "    'team2_coach_id',\n",
    "    'team1_win', \n",
    "    'team2_win', \n",
    "    'team1_race_name', \n",
    "    'team2_race_name'\n",
    "]\n",
    "\n",
    "#final dataframe \n",
    "new_df = df_matches[selected_columns].copy()\n",
    "new_df['team1_race_name'] = new_df['team1_race_name'].astype('category')\n",
    "new_df['team2_race_name'] = new_df['team2_race_name'].astype('category')\n",
    "\n",
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the cleaned data in your local directory \n",
    "new_df.to_csv('../df_matches_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "42186_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
